{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "LSTM-IMDBSubwords8k.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNCsk9rLxFr3ulofeTYsoE8",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hrushikute/DataAnalytics/blob/master/LSTM_IMDBSubwords8k.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **LSTM on IMDB dataset**\n"
      ],
      "metadata": {
        "id": "yeTYpg90cCP7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Downaload the data"
      ],
      "metadata": {
        "id": "sI1OMDpXcMlx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow_datasets as tfds\n",
        "# Download the subword encoded pretokenized data set\n",
        "dataset, info = tfds.load(\"imdb_reviews/subwords8k\", with_info=True, as_supervised=True)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vKcOHqFlcLmY",
        "outputId": "53768e98-d915-43be-c64b-71b16b2993d0"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:TFDS datasets with text encoding are deprecated and will be removed in a future version. Instead, you should use the plain text version and tokenize the text using `tensorflow_text` (See: https://www.tensorflow.org/tutorials/tensorflow_text/intro#tfdata_example)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset ,info"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gil8ntO4cvcA",
        "outputId": "e71cae43-a21b-4a36-d45c-bcc30542640e"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "({'test': <PrefetchDataset element_spec=(TensorSpec(shape=(None,), dtype=tf.int64, name=None), TensorSpec(shape=(), dtype=tf.int64, name=None))>,\n",
              "  'train': <PrefetchDataset element_spec=(TensorSpec(shape=(None,), dtype=tf.int64, name=None), TensorSpec(shape=(), dtype=tf.int64, name=None))>,\n",
              "  'unsupervised': <PrefetchDataset element_spec=(TensorSpec(shape=(None,), dtype=tf.int64, name=None), TensorSpec(shape=(), dtype=tf.int64, name=None))>},\n",
              " tfds.core.DatasetInfo(\n",
              "     name='imdb_reviews',\n",
              "     version=1.0.0,\n",
              "     description='Large Movie Review Dataset.\n",
              " This is a dataset for binary sentiment classification containing substantially more data than previous benchmark datasets. We provide a set of 25,000 highly polar movie reviews for training, and 25,000 for testing. There is additional unlabeled data for use as well.',\n",
              "     homepage='http://ai.stanford.edu/~amaas/data/sentiment/',\n",
              "     features=FeaturesDict({\n",
              "         'label': ClassLabel(shape=(), dtype=tf.int64, num_classes=2),\n",
              "         'text': Text(shape=(None,), dtype=tf.int64, encoder=<SubwordTextEncoder vocab_size=8185>),\n",
              "     }),\n",
              "     total_num_examples=100000,\n",
              "     splits={\n",
              "         'test': 25000,\n",
              "         'train': 25000,\n",
              "         'unsupervised': 50000,\n",
              "     },\n",
              "     supervised_keys=('text', 'label'),\n",
              "     citation=\"\"\"@InProceedings{maas-EtAl:2011:ACL-HLT2011,\n",
              "       author    = {Maas, Andrew L.  and  Daly, Raymond E.  and  Pham, Peter T.  and  Huang, Dan  and  Ng, Andrew Y.  and  Potts, Christopher},\n",
              "       title     = {Learning Word Vectors for Sentiment Analysis},\n",
              "       booktitle = {Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies},\n",
              "       month     = {June},\n",
              "       year      = {2011},\n",
              "       address   = {Portland, Oregon, USA},\n",
              "       publisher = {Association for Computational Linguistics},\n",
              "       pages     = {142--150},\n",
              "       url       = {http://www.aclweb.org/anthology/P11-1015}\n",
              "     }\"\"\",\n",
              "     redistribution_info=,\n",
              " ))"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Get the tokenizer\n",
        "tokenizer = info.features['text'].encoder"
      ],
      "metadata": {
        "id": "t0Hs3UW7eLQP"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "BUFFETR_SIZE = 10000\n",
        "BATCH_SIZE = 256\n",
        "\n",
        "# Get traina nd test split\n",
        "train_data, test_data = dataset['train'],dataset['test']\n",
        "print(len(train_data), len(test_data))\n",
        "print(type(train_data))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QpNvrvWleqIH",
        "outputId": "a3a777ab-70c5-4841-c8c3-56122e0a514c"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "25000 25000\n",
            "<class 'tensorflow.python.data.ops.dataset_ops.PrefetchDataset'>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Shuffle the training data\n",
        "train_dataset = train_data.shuffle(BUFFETR_SIZE)\n",
        "\n",
        "# Batch and Padd the data\n",
        "\n",
        "train_dataset = train_dataset.padded_batch(BATCH_SIZE)\n",
        "test_dataset = test_data.padded_batch(BATCH_SIZE)"
      ],
      "metadata": {
        "id": "J_S-uaFHfL8d"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Build and Compile the model"
      ],
      "metadata": {
        "id": "CRanAQDjiftZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "\n",
        "# Hyper parameters\n",
        "batch_size=1\n",
        "timesteps = 20\n",
        "features = 16\n",
        "lstm_dim = 8\n",
        "\n",
        "# lets have array with random values\n",
        "random_input = np.random.rand(batch_size, timesteps, features)\n",
        "print(f'Shape of array {random_input.shape}')\n",
        "\n",
        "\n",
        "# Define LSTM that return single output.\n",
        "lstm=tf.keras.layers.LSTM(lstm_dim)\n",
        "result = lstm(random_input)\n",
        "print(f'Result : {result}')\n",
        "\n",
        "# Define LSTM that retruns a sequence\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4NKpSeLqicxp",
        "outputId": "d3483989-d243-4562-e254-e895de70c180"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of array (1, 20, 16)\n",
            "Result : [[-0.11051227  0.31303272  0.25312325 -0.437785    0.12659463 -0.17075601\n",
            "  -0.12276196  0.00838692]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "-eyejeZGjVwZ"
      },
      "execution_count": 15,
      "outputs": []
    }
  ]
}